{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47a21bc4-cd0a-4c21-8994-98e06bbc13c8",
   "metadata": {},
   "source": [
    "# Now that the hypothesis is tested, I'm trying to find a good data format for the masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8d4943f-865f-4cf2-8f87-cf35658a0a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "import torch\n",
    "import random\n",
    "import copy\n",
    "import itertools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "874d83c4-21cc-4fdd-a464-e653a4979de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"TurkuNLP/bert-base-finnish-cased-v1\"\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = transformers.AutoModelForPreTraining.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08ddbf0d-684d-4c05-b4c3-a2f7beb5da4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]']\n"
     ]
    }
   ],
   "source": [
    "special_tokens = tokenizer.all_special_tokens\n",
    "print(special_tokens)\n",
    "continuation_marker = \"##\"   # how to get this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcd58ce6-7d07-4e47-923f-d36220071629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertTokenizerFast(name_or_path='TurkuNLP/bert-base-finnish-cased-v1', vocab_size=50105, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t101: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t102: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t103: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t104: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      "[<class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>, <class 'transformers.tokenization_utils_fast.PreTrainedTokenizerFast'>, <class 'transformers.tokenization_utils_base.PreTrainedTokenizerBase'>, <class 'transformers.tokenization_utils_base.SpecialTokensMixin'>, <class 'transformers.utils.hub.PushToHubMixin'>, <class 'object'>]\n",
      "['BertTokenizer', 'BertTokenizerFast', 'List', 'Optional', 'PRETRAINED_INIT_CONFIGURATION', 'PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES', 'PRETRAINED_VOCAB_FILES_MAP', 'PreTrainedTokenizerFast', 'Tuple', 'VOCAB_FILES_NAMES', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'json', 'logger', 'logging', 'normalizers']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer)\n",
    "print(tokenizer.__class__.mro())\n",
    "print(dir(transformers.models.bert.tokenization_bert_fast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "90de0298-a2bc-4d52-b627-a93e525106d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "def mask(text, tokenizer):\n",
    "\n",
    "    def get_indices(t):\n",
    "        converted = tokenizer.convert_ids_to_tokens(t[\"input_ids\"][0])\n",
    "        indices=[]\n",
    "        for i in range(0, len(t[\"input_ids\"][0])):\n",
    "            if converted[i][:2] != continuation_marker and converted[i] not in special_tokens:\n",
    "                indices.append([i])\n",
    "            else:\n",
    "                if converted[i] not in special_tokens and indices!=[]:   # here we are only skipping the fact that first token is a special token; indices is empty.\n",
    "                    indices[-1].append(i)\n",
    "        return indices   \n",
    "    \n",
    "    t = tokenizer(text, return_tensors='pt') # prepare normal tokenized input\n",
    "    indices = get_indices(t)\n",
    "\n",
    "    return indices, t, tokenizer.decode(t.input_ids[0])\n",
    "\n",
    "\n",
    "\n",
    "def find_same_tokens(lst, index):\n",
    "    target_value = lst[index]\n",
    "    return [i for i, value in enumerate(lst) if value == target_value and i != index]\n",
    "\n",
    "\n",
    "\n",
    "def context_aware_mask(text, tokenizer):\n",
    "\n",
    "    def get_indices(t,t2):\n",
    "        converted = tokenizer.convert_ids_to_tokens(t[\"input_ids\"][0])\n",
    "        indices=[]\n",
    "        indices_context = []\n",
    "        for i in range(0, len(t[\"input_ids\"][0])):\n",
    "            #same_tokens = [j for j in range(len(t2[\"input_ids\"][0])) if t2[\"input_ids\"][0][j] == t2[\"input_ids\"][0][i]]\n",
    "            #same_tokens = [j for j in same_tokens if j != i]\n",
    "            same_tokens = find_same_tokens(t2[\"input_ids\"][0], i)\n",
    "            #print(same_tokens==same_tokens2)\n",
    "            print(tokenizer.convert_ids_to_tokens(t2[\"input_ids\"][0][same_tokens]))\n",
    "            if converted[i][:2] != continuation_marker and converted[i] not in special_tokens:\n",
    "                indices.append([i])\n",
    "                if same_tokens != [] and converted[i] not in string.punctuation:\n",
    "                    indices_context.append(same_tokens)\n",
    "                else:\n",
    "                    indices_context.append([])\n",
    "            else:\n",
    "                if converted[i] not in special_tokens and indices!=[]:   # here we are only skipping the fact that first token is a special token; indices is empty.\n",
    "                    indices[-1].append(i)\n",
    "                    if same_tokens != [] and converted[i] not in string.punctuation:\n",
    "                        for j in same_tokens:\n",
    "                            indices_context[-1].append(j)\n",
    "                    #else:\n",
    "                        #indices_context.append([])\n",
    "        return indices, indices_context  \n",
    "    \n",
    "    t = tokenizer(text, return_tensors='pt') # prepare normal tokenized input\n",
    "    #t_lower = tokenizer(text.lower(), return_tensors='pt')\n",
    "    print(len(t.input_ids[0]), len(t_lower.input_ids[0]))\n",
    "    indices, indices_context = get_indices(t,t_lower)\n",
    "\n",
    "    return indices, t, tokenizer.decode(t.input_ids[0]), indices_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "20fbf58a-0cd8-45f3-b287-7725f1a4877a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22 23\n",
      "[]\n",
      "[]\n",
      "[',']\n",
      "[]\n",
      "['am']\n",
      "['##and']\n",
      "['##a']\n",
      "[',']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "['am']\n",
      "['##and']\n",
      "['##a']\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[]\n",
      "[1] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda @ outlook. com [SEP]\n",
      "[2] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda @ outlook. com [SEP]\n",
      "[3] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda @ outlook. com [SEP]\n",
      "[4, 5] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda @ outlook. com [SEP]\n",
      "[6] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda @ outlook. com [SEP]\n",
      "[7] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda @ outlook. com [SEP]\n",
      "[8] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda @ outlook. com [SEP]\n",
      "[9] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda @ outlook. com [SEP]\n",
      "[10] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda @ outlook. com [SEP]\n",
      "[11] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda @ outlook. com [SEP]\n",
      "[12, 13, 14] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda @ outlook. com [SEP]\n",
      "[15] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda @ outlook. com [SEP]\n",
      "[16, 17, 18] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda @ outlook. com [SEP]\n",
      "[19] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda @ outlook. com [SEP]\n",
      "[20] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda @ outlook. com [SEP]\n",
      "[[], [], [], [13, 14], [], [2], [], [], [], [], [4, 5], [], [], [], []]\n",
      "[[1], [2], [3], [4, 5], [6], [7], [8], [9], [10], [11], [12, 13, 14], [15], [16, 17, 18], [19], [20]]\n"
     ]
    }
   ],
   "source": [
    "text = \"Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda@outlook.com\"\n",
    "masked_indices, tokenized_text, decoded_text, context = context_aware_mask(text, tokenizer)\n",
    "for i in masked_indices:\n",
    "    print(i, decoded_text)#,tokenized_text)\n",
    "print(context)\n",
    "print(masked_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b198c6b3-9c4d-4c1e-b3a1-b5992487d385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_probability(A):\n",
    "    softmax = torch.nn.Softmax(dim=0)\n",
    "    return softmax(A)\n",
    "\n",
    "def predict(masked, i, true_token, print_results=False, top=10):\n",
    "    # do a prediction\n",
    "    model_out = model(**masked)\n",
    "    logits = model_out[\"prediction_logits\"]\n",
    "\n",
    "    # logits for this word specifically\n",
    "    logits_i = logits[0,i,:]  # this contains the probabilities for this token\n",
    "    # change to probability\n",
    "    probs = to_probability(logits_i)\n",
    "    # true token is the index\n",
    "    word_probability = probs[true_token]\n",
    "\n",
    "    # Do only in debug mode:\n",
    "    if print_results:\n",
    "        print(f'{tokenizer.decode(true_token)} has probability {word_probability}')\n",
    "        # see 10 top predictions for debug\n",
    "        top_logits, top_tokens= torch.sort(logits, dim=2, descending=True)#[:,:,:top]\n",
    "        top_probs = to_probability(top_logits[0,i,:])\n",
    "        top_logits = top_logits[:,:,:top]\n",
    "        top_tokens = top_tokens[:,:,:top]\n",
    "\n",
    "    \n",
    "        print(\"Guesses:\",tokenizer.decode(top_tokens[0,i,:]))\n",
    "        print(\"Logits: \",top_logits[0,i,:])\n",
    "        print(\"Probs:  \",top_probs[:top])\n",
    "    return word_probability\n",
    "\n",
    "\n",
    "def get_scores(to_be_masked, tokens, context=[], debug=False):\n",
    "    \"\"\"\n",
    "    Calculates the (aggregated) probability of the given word based on the model prediction.\n",
    "    For multi-subtoken words, aggregation strategy is gradual unmasking and multiplication.\n",
    "    Input: \n",
    "        tokens: tokenizer output for a span of text\n",
    "        to_be_masked: indices for which are masked from the tokens and over which we calculate\n",
    "                      i.e. indices of the subtokens that form a word.\n",
    "        debug (False): prints out extra information if True\n",
    "    Returns:\n",
    "        (aggregated) probability \\in (0,1)\n",
    "    \"\"\"\n",
    "    # initialize the score; we're multiplying, so 1\n",
    "    final_score = 1\n",
    "\n",
    "    # loop over the subtokens of a word\n",
    "    for i in range(len(to_be_masked)):\n",
    "        # making a deep copy as tensors are nested and yada yada\n",
    "        t = copy.deepcopy(tokens)\n",
    "        current = to_be_masked[i:]   # this is the token we are CURRENTLY interested in\n",
    "        for j in current:\n",
    "            t[\"input_ids\"][0][j] = tokenizer.mask_token_id     # we mask the SUBtokens that are in current\n",
    "        if context != []:\n",
    "            for j in context:\n",
    "                t[\"input_ids\"][0][j] = tokenizer.mask_token_id \n",
    "        if debug:\n",
    "            print(tokenizer.decode(t[\"input_ids\"][0]))\n",
    "        # multiply the final score with the predicted probability => aggregates over to_be_masked==one word\n",
    "        final_score *= predict(t, current[0], tokens.input_ids[0][current[0]], print_results=debug)\n",
    "        \n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59fb3bc0-00be-487a-99b5-c7db6e654560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK], olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda @ outlook. com [SEP]\n",
      "Moi has probability 0.11406373977661133\n",
      "Guesses: Hei Moi Niin Muuten Juu Minä Eli hei Joo Elikkäs\n",
      "Logits:  tensor([17.7679, 16.0247, 14.8126, 14.2221, 13.8727, 13.8700, 13.7817, 13.7731,\n",
      "        13.6180, 13.1582], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.6519, 0.1141, 0.0339, 0.0188, 0.0133, 0.0132, 0.0121, 0.0120, 0.0103,\n",
      "        0.0065], grad_fn=<SliceBackward0>)\n",
      "Moi \t >> 0.11406373977661133\n",
      "[CLS] Moi [MASK] olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda @ outlook. com [SEP]\n",
      ", has probability 0.9137153029441833\n",
      "Guesses: , ja! : minä mä Moi Minäkka -\n",
      "Logits:  tensor([18.6358, 15.2468, 14.9866, 12.9545, 12.6414, 12.4402, 12.0816, 12.0571,\n",
      "        12.0222, 11.8171], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.9137, 0.0308, 0.0238, 0.0031, 0.0023, 0.0019, 0.0013, 0.0013, 0.0012,\n",
      "        0.0010], grad_fn=<SliceBackward0>)\n",
      ", \t >> 0.9137153029441833\n",
      "[CLS] Moi, [MASK] Amanda, mulle voit laittaa viestiä osoitteeseen amanda @ outlook. com [SEP]\n",
      "olen has probability 0.09167784452438354\n",
      "Guesses: Hei hei olen Moi ihana oon sinä kiitos olet rakas\n",
      "Logits:  tensor([13.9002, 13.6827, 13.2186, 13.0385, 12.6649, 12.0229, 11.9305, 11.8677,\n",
      "        11.8476, 11.8309], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.1812, 0.1458, 0.0917, 0.0766, 0.0527, 0.0277, 0.0253, 0.0237, 0.0233,\n",
      "        0.0229], grad_fn=<SliceBackward0>)\n",
      "olen \t >> 0.09167784452438354\n",
      "[CLS] Moi, olen [MASK] [MASK], mulle voit laittaa viestiä osoitteeseen am [MASK] [MASK] @ outlook. com [SEP]\n",
      "Aman has probability 0.0013468164252117276\n",
      "Guesses: kiinnostunut am ihan täällä siis jo vasta aivan myös Jenni\n",
      "Logits:  tensor([8.5825, 8.5818, 8.4711, 8.2639, 8.2294, 8.1356, 7.9304, 7.7926, 7.7430,\n",
      "        7.6903], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.0169, 0.0169, 0.0151, 0.0123, 0.0119, 0.0108, 0.0088, 0.0077, 0.0073,\n",
      "        0.0069], grad_fn=<SliceBackward0>)\n",
      "[CLS] Moi, olen Aman [MASK], mulle voit laittaa viestiä osoitteeseen am [MASK] [MASK] @ outlook. com [SEP]\n",
      "##da has probability 0.0007302805315703154\n",
      "Guesses: sisko äiti fani poika tyttö tytär takana kirjoittaja kanssa Jenni\n",
      "Logits:  tensor([11.7263, 11.2412, 11.0493, 10.8505, 10.8340, 10.8198, 10.7733, 10.4215,\n",
      "        10.3121, 10.0604], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.0865, 0.0533, 0.0440, 0.0360, 0.0355, 0.0350, 0.0334, 0.0235, 0.0210,\n",
      "        0.0164], grad_fn=<SliceBackward0>)\n",
      "Amanda \t >> 9.835538321567583e-07\n",
      "[CLS] Moi, olen Amanda [MASK] mulle voit laittaa viestiä osoitteeseen amanda @ outlook. com [SEP]\n",
      ", has probability 0.1578485667705536\n",
      "Guesses: ja, eli joten mutta mut -. niin Ja\n",
      "Logits:  tensor([18.6025, 16.9626, 13.6959, 13.5734, 13.5618, 12.1303, 12.0778, 11.8731,\n",
      "        11.8498, 11.7116], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.8136, 0.1578, 0.0060, 0.0053, 0.0053, 0.0013, 0.0012, 0.0010, 0.0010,\n",
      "        0.0008], grad_fn=<SliceBackward0>)\n",
      ", \t >> 0.1578485667705536\n",
      "[CLS] Moi [MASK] olen Amanda, [MASK] voit laittaa viestiä osoitteeseen amanda @ outlook. com [SEP]\n",
      "mulle has probability 0.012609654106199741\n",
      "Guesses: joten ja mutta eli minulle niin mulle mut minusta sinä\n",
      "Logits:  tensor([17.1790, 16.4803, 16.3021, 15.7135, 15.4820, 15.1897, 13.8329, 13.5296,\n",
      "        13.3015, 13.2648], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.3580, 0.1780, 0.1489, 0.0827, 0.0656, 0.0490, 0.0126, 0.0093, 0.0074,\n",
      "        0.0071], grad_fn=<SliceBackward0>)\n",
      "mulle \t >> 0.012609654106199741\n",
      "[CLS] Moi, olen Amanda, mulle [MASK] laittaa viestiä osoitteeseen amanda @ outlook. com [SEP]\n",
      "voit has probability 0.12811265885829926\n",
      "Guesses: voi voit saa voitte kannattaa voisi voipi voisit pitää voin\n",
      "Logits:  tensor([20.9967, 19.2617, 18.8679, 16.9877, 16.8955, 16.5403, 15.9269, 15.8915,\n",
      "        15.7447, 15.6481], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.7263, 0.1281, 0.0864, 0.0132, 0.0120, 0.0084, 0.0046, 0.0044, 0.0038,\n",
      "        0.0035], grad_fn=<SliceBackward0>)\n",
      "voit \t >> 0.12811265885829926\n",
      "[CLS] Moi, olen Amanda, mulle voit [MASK] viestiä osoitteeseen amanda @ outlook. com [SEP]\n",
      "laittaa has probability 0.8577250242233276\n",
      "Guesses: laittaa lähettää pistää heittää jättää kirjoittaa laitta laitaa laita kirjoitella\n",
      "Logits:  tensor([22.2289, 19.9987, 18.6992, 17.7726, 17.4084, 16.2098, 15.3629, 15.3378,\n",
      "        14.4907, 14.2375], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([8.5773e-01, 9.2209e-02, 2.5144e-02, 9.9540e-03, 6.9155e-03, 2.0858e-03,\n",
      "        8.9428e-04, 8.7214e-04, 3.7383e-04, 2.9022e-04],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "laittaa \t >> 0.8577250242233276\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa [MASK] osoitteeseen amanda @ outlook. com [SEP]\n",
      "viestiä has probability 0.15111681818962097\n",
      "Guesses: sähköpostia postia viestiä viestin viestejä palautetta kysymyksiä terveisiä osoitteen kommenttia\n",
      "Logits:  tensor([20.5953, 19.5548, 19.2062, 16.4787, 14.9719, 14.6786, 14.6224, 14.4660,\n",
      "        14.3989, 14.2414], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.6062, 0.2141, 0.1511, 0.0099, 0.0022, 0.0016, 0.0015, 0.0013, 0.0012,\n",
      "        0.0011], grad_fn=<SliceBackward0>)\n",
      "viestiä \t >> 0.15111681818962097\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä [MASK] amanda @ outlook. com [SEP]\n",
      "osoitteeseen has probability 0.5203199982643127\n",
      "Guesses: osoitteeseen : sähköpostilla, mulle osoitteesta sähköpostiin. osoitteessa vaikka\n",
      "Logits:  tensor([17.3572, 16.9604, 14.7929, 13.5082, 13.0458, 12.9443, 12.9333, 12.8929,\n",
      "        12.8766, 12.7626], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.5203, 0.3499, 0.0401, 0.0111, 0.0070, 0.0063, 0.0062, 0.0060, 0.0059,\n",
      "        0.0053], grad_fn=<SliceBackward0>)\n",
      "osoitteeseen \t >> 0.5203199982643127\n",
      "[CLS] Moi, olen [MASK] [MASK], mulle voit laittaa viestiä osoitteeseen [MASK] [MASK] [MASK] @ outlook. com [SEP]\n",
      "am has probability 0.0014363426016643643\n",
      "Guesses: j w an mar mi : ma i jaa pa\n",
      "Logits:  tensor([8.6759, 8.6417, 8.4064, 8.2373, 8.0146, 7.8709, 7.7611, 7.6313, 7.5792,\n",
      "        7.5259], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.0166, 0.0160, 0.0127, 0.0107, 0.0086, 0.0074, 0.0066, 0.0058, 0.0055,\n",
      "        0.0053], grad_fn=<SliceBackward0>)\n",
      "[CLS] Moi, olen [MASK] [MASK], mulle voit laittaa viestiä osoitteeseen am [MASK] [MASK] @ outlook. com [SEP]\n",
      "##and has probability 3.4637728276720736e-06\n",
      "Guesses: . - _ : / @'am, &\n",
      "Logits:  tensor([14.0522, 13.4097, 12.2547, 10.7148, 10.6603, 10.0833,  9.5203,  8.9898,\n",
      "         8.9757,  8.7876], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.4738, 0.2492, 0.0785, 0.0168, 0.0159, 0.0090, 0.0051, 0.0030, 0.0030,\n",
      "        0.0025], grad_fn=<SliceBackward0>)\n",
      "[CLS] Moi, olen [MASK] [MASK], mulle voit laittaa viestiä osoitteeseen amand [MASK] @ outlook. com [SEP]\n",
      "##a has probability 0.000749394588638097\n",
      "Guesses: _. -, @ ( a info o ville\n",
      "Logits:  tensor([11.8000, 10.8800, 10.0971,  9.5527,  9.5250,  9.4414,  9.2176,  8.4279,\n",
      "         8.4202,  8.3753], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.2096, 0.0835, 0.0382, 0.0222, 0.0215, 0.0198, 0.0158, 0.0072, 0.0071,\n",
      "        0.0068], grad_fn=<SliceBackward0>)\n",
      "amanda \t >> 3.7283613696370566e-12\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda [MASK] outlook. com [SEP]\n",
      "@ has probability 0.996116042137146\n",
      "Guesses: @ ät at. - _ a ( ei )\n",
      "Logits:  tensor([23.9237, 17.9361, 16.7778, 16.1620, 14.1469, 14.0147, 12.7919, 12.3484,\n",
      "        11.8031, 11.4288], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([9.9612e-01, 2.5001e-03, 7.8509e-04, 4.2408e-04, 5.6533e-05, 4.9533e-05,\n",
      "        1.4583e-05, 9.3595e-06, 5.4254e-06, 3.7313e-06],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "@ \t >> 0.996116042137146\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda @ [MASK] [MASK] [MASK]. com [SEP]\n",
      "out has probability 0.013344630599021912\n",
      "Guesses: y j b wor out gmail hotmail sun w netti\n",
      "Logits:  tensor([16.9299, 13.4653, 13.4413, 13.2676, 12.9080, 12.7317, 12.5645, 12.3131,\n",
      "        12.1482, 11.8512], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.7447, 0.0233, 0.0227, 0.0191, 0.0133, 0.0112, 0.0095, 0.0074, 0.0062,\n",
      "        0.0046], grad_fn=<SliceBackward0>)\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda @ out [MASK] [MASK]. com [SEP]\n",
      "##lo has probability 0.008268083445727825\n",
      "Guesses: ##ahadpootoonshoweicna\n",
      "Logits:  tensor([16.6913, 16.2077, 16.0966, 16.0026, 15.9894, 15.9575, 15.9367, 15.8525,\n",
      "        15.6224, 15.5979], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.0772, 0.0476, 0.0426, 0.0387, 0.0382, 0.0370, 0.0363, 0.0333, 0.0265,\n",
      "        0.0259], grad_fn=<SliceBackward0>)\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda @ outlo [MASK]. com [SEP]\n",
      "##ok has probability 0.014438992366194725\n",
      "Guesses: ##ookeroiroonressideckxs\n",
      "Logits:  tensor([19.3211, 17.6528, 17.6436, 17.1700, 16.9754, 16.7322, 16.5898, 16.5218,\n",
      "        16.5169, 16.4402], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.3254, 0.0614, 0.0608, 0.0379, 0.0312, 0.0244, 0.0212, 0.0198, 0.0197,\n",
      "        0.0183], grad_fn=<SliceBackward0>)\n",
      "outlook \t >> 1.5931193502183305e-06\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda @ outlook [MASK] com [SEP]\n",
      ". has probability 0.9999407529830933\n",
      "Guesses: . piste com'@ [UNK], - : fi\n",
      "Logits:  tensor([27.1775, 16.8643, 16.0691, 13.8665, 13.8325, 13.8167, 13.7925, 13.1253,\n",
      "        13.1058, 12.0564], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([9.9994e-01, 3.3192e-05, 1.4985e-05, 1.6561e-06, 1.6007e-06, 1.5757e-06,\n",
      "        1.5380e-06, 7.8919e-07, 7.7399e-07, 2.7101e-07],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ". \t >> 0.9999407529830933\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda @ outlook. [MASK] [SEP]\n",
      "com has probability 0.8941932320594788\n",
      "Guesses: com fi net de org fr in ee ch info\n",
      "Logits:  tensor([22.4796, 20.2274, 17.6198, 15.7413, 15.4267, 14.4072, 14.3386, 14.2329,\n",
      "        14.1408, 14.0805], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([8.9419e-01, 9.4039e-02, 6.9317e-03, 1.0593e-03, 7.7336e-04, 2.7901e-04,\n",
      "        2.6051e-04, 2.3438e-04, 2.1376e-04, 2.0125e-04],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "com \t >> 0.8941932320594788\n"
     ]
    }
   ],
   "source": [
    "for ind, cont in zip(masked_indices, context):\n",
    "    final_score = get_scores(ind, tokenized_text, context = cont, debug=True)\n",
    "    word = tokenizer.decode(tokenized_text[\"input_ids\"][0][ind])\n",
    "    print(f'{word} \\t >> {final_score}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5537391f-7d62-43f5-9585-630f2ab0f04f",
   "metadata": {},
   "source": [
    " ## Actual function \n",
    "\n",
    " Also testing the hypothesis that email screws names over..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d4f76cf-02e6-44e5-891c-5f634ecc5c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moi \t >> 0.11190123856067657\n",
      ", \t >> 0.9145289063453674\n",
      "olen \t >> 0.09335323423147202\n",
      "Amanda \t >> 2.389621840848122e-06 \t >> Redact\n",
      ", \t >> 0.15858927369117737\n",
      "mulle \t >> 0.00788317620754242\n",
      "voit \t >> 0.12527547776699066\n",
      "laittaa \t >> 0.8456868529319763\n",
      "viestiä \t >> 0.15869389474391937\n",
      "osoitteeseen \t >> 0.5966542363166809\n",
      "example \t >> 6.858204004700497e-10 \t >> Redact\n",
      "@ \t >> 0.995366096496582\n",
      "outlook \t >> 3.7645963857357856e-06 \t >> Redact\n",
      ". \t >> 0.9999146461486816\n",
      "com \t >> 0.9127006530761719\n"
     ]
    }
   ],
   "source": [
    "threshold = 1e-4\n",
    "text = \"Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen example@outlook.com\"\n",
    "masked_indices, tokenized_text, decoded_text = mask(text, tokenizer)\n",
    "for ind in masked_indices:\n",
    "    final_score = get_scores(ind, tokenized_text, debug=False)\n",
    "    word = tokenizer.decode(tokenized_text[\"input_ids\"][0][ind])\n",
    "    if final_score < threshold:\n",
    "        print(f'{word} \\t >> {final_score} \\t >> Redact')\n",
    "    else:\n",
    "        print(f'{word} \\t >> {final_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebbebce5-2b37-4088-a895-087fdfdf6218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moi \t >> 0.11406373977661133\n",
      ", \t >> 0.9137153029441833\n",
      "olen \t >> 0.09167784452438354\n",
      "Amanda \t >> 0.000740985618904233\n",
      ", \t >> 0.1578485667705536\n",
      "mulle \t >> 0.008461282588541508\n",
      "voit \t >> 0.12811265885829926\n",
      "laittaa \t >> 0.8577250242233276\n",
      "viestiä \t >> 0.15111681818962097\n",
      "osoitteeseen \t >> 0.5203199982643127\n",
      "amanda \t >> 0.0005004298291169107\n",
      "@ \t >> 0.996116042137146\n",
      "outlook \t >> 1.5931193502183305e-06 \t >> Redact\n",
      ". \t >> 0.9999407529830933\n",
      "com \t >> 0.8941932320594788\n"
     ]
    }
   ],
   "source": [
    "text = \"Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda@outlook.com\"\n",
    "masked_indices, tokenized_text, decoded_text = mask(text, tokenizer)\n",
    "for ind in masked_indices:\n",
    "    final_score = get_scores(ind, tokenized_text, debug=False)\n",
    "    word = tokenizer.decode(tokenized_text[\"input_ids\"][0][ind])\n",
    "    if final_score < threshold:\n",
    "        print(f'{word} \\t >> {final_score} \\t >> Redact')\n",
    "    else:\n",
    "        print(f'{word} \\t >> {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78de29a5-f5bf-4ac6-a92b-9999356a9255",
   "metadata": {},
   "source": [
    "Sliding window needed...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec8cda5e-535d-4528-8815-529585a04fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK], olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda. a. myntti @ utu. fi [SEP]\n",
      "Moi has probability 0.09783897548913956\n",
      "Guesses: Hei Moi Niin Muuten Juu hei Joo Minä Eli Kiitos\n",
      "Logits:  tensor([18.0196, 16.0267, 14.7276, 14.0297, 13.9221, 13.8744, 13.7270, 13.6844,\n",
      "        13.5303, 13.0911], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.7178, 0.0978, 0.0267, 0.0133, 0.0119, 0.0114, 0.0098, 0.0094, 0.0081,\n",
      "        0.0052], grad_fn=<SliceBackward0>)\n",
      "Moi \t >> 0.09783897548913956\n",
      "[CLS] Moi [MASK] olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda. a. myntti @ utu. fi [SEP]\n",
      ", has probability 0.9152221083641052\n",
      "Guesses: , ja! :kka Moi mä minä - kun\n",
      "Logits:  tensor([18.5762, 14.9539, 14.9508, 13.2646, 12.7153, 12.5751, 12.1283, 12.1190,\n",
      "        11.9380, 11.7797], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.9152, 0.0245, 0.0244, 0.0045, 0.0026, 0.0023, 0.0014, 0.0014, 0.0012,\n",
      "        0.0010], grad_fn=<SliceBackward0>)\n",
      ", \t >> 0.9152221083641052\n",
      "[CLS] Moi, [MASK] Amanda, mulle voit laittaa viestiä osoitteeseen amanda. a. myntti @ utu. fi [SEP]\n",
      "olen has probability 0.05866984277963638\n",
      "Guesses: Hei hei Moi olen ihana rakas sinä kiitos oon ja\n",
      "Logits:  tensor([14.1292, 14.0475, 13.0499, 12.8344, 12.2256, 12.0267, 11.9355, 11.8929,\n",
      "        11.7187, 11.6651], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.2142, 0.1974, 0.0728, 0.0587, 0.0319, 0.0262, 0.0239, 0.0229, 0.0192,\n",
      "        0.0182], grad_fn=<SliceBackward0>)\n",
      "olen \t >> 0.05866984277963638\n",
      "[CLS] Moi, olen [MASK] [MASK], mulle voit laittaa viestiä osoitteeseen amanda. a. myntti @ utu. fi [SEP]\n",
      "Aman has probability 0.009322100318968296\n",
      "Guesses: kiinnostunut am täällä ihan vasta siis Aman jo Jenni aivan\n",
      "Logits:  tensor([9.5674, 9.2939, 9.0420, 8.5219, 8.4901, 8.2941, 8.2412, 8.1654, 8.0317,\n",
      "        7.8382], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.0351, 0.0267, 0.0208, 0.0123, 0.0120, 0.0098, 0.0093, 0.0086, 0.0076,\n",
      "        0.0062], grad_fn=<SliceBackward0>)\n",
      "[CLS] Moi, olen Aman [MASK], mulle voit laittaa viestiä osoitteeseen amanda. a. myntti @ utu. fi [SEP]\n",
      "##da has probability 0.05213552340865135\n",
      "Guesses: ##adasatajassaissaia kirjoittajai\n",
      "Logits:  tensor([12.1254, 11.1853, 10.7317, 10.6240, 10.5246, 10.0528,  9.8527,  9.7535,\n",
      "         9.7306,  9.6520], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.1335, 0.0521, 0.0331, 0.0297, 0.0269, 0.0168, 0.0138, 0.0125, 0.0122,\n",
      "        0.0113], grad_fn=<SliceBackward0>)\n",
      "Amanda \t >> 0.00048601257731206715 \t >> Redact\n",
      "[CLS] Moi, olen Amanda [MASK] mulle voit laittaa viestiä osoitteeseen amanda. a. myntti @ utu. fi [SEP]\n",
      ", has probability 0.15173020958900452\n",
      "Guesses: ja, eli joten mutta -. mut Ja!\n",
      "Logits:  tensor([18.8184, 17.1285, 13.9340, 13.5213, 13.4964, 12.3079, 12.2653, 12.2091,\n",
      "        12.0952, 12.0819], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.8222, 0.1517, 0.0062, 0.0041, 0.0040, 0.0012, 0.0012, 0.0011, 0.0010,\n",
      "        0.0010], grad_fn=<SliceBackward0>)\n",
      ", \t >> 0.15173020958900452\n",
      "[CLS] Moi, olen Amanda, [MASK] voit laittaa viestiä osoitteeseen amanda. a. myntti @ utu. fi [SEP]\n",
      "mulle has probability 0.005366495344787836\n",
      "Guesses: joten ja mutta eli minulle niin minusta nyt mulle mut\n",
      "Logits:  tensor([17.9620, 16.8124, 16.7235, 15.9874, 15.7551, 15.1396, 14.0246, 13.6029,\n",
      "        13.4692, 13.4233], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.4796, 0.1519, 0.1390, 0.0666, 0.0528, 0.0285, 0.0094, 0.0061, 0.0054,\n",
      "        0.0051], grad_fn=<SliceBackward0>)\n",
      "mulle \t >> 0.005366495344787836 \t >> Redact\n",
      "[CLS] Moi, olen Amanda, mulle [MASK] laittaa viestiä osoitteeseen amanda. a. myntti @ utu. fi [SEP]\n",
      "voit has probability 0.1366426795721054\n",
      "Guesses: voi voit saa kannattaa voitte voisi voipi voisit voin pitää\n",
      "Logits:  tensor([21.0307, 19.3314, 18.5237, 16.9238, 16.8049, 16.3596, 15.9170, 15.8855,\n",
      "        15.6609, 15.6442], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.7475, 0.1366, 0.0609, 0.0123, 0.0109, 0.0070, 0.0045, 0.0044, 0.0035,\n",
      "        0.0034], grad_fn=<SliceBackward0>)\n",
      "voit \t >> 0.1366426795721054\n",
      "[CLS] Moi, olen Amanda, mulle voit [MASK] viestiä osoitteeseen amanda. a. myntti @ utu. fi [SEP]\n",
      "laittaa has probability 0.876126229763031\n",
      "Guesses: laittaa lähettää pistää heittää jättää kirjoittaa laitta laitaa laita kirjoitella\n",
      "Logits:  tensor([22.4297, 20.0312, 18.8381, 17.6209, 17.3614, 16.2856, 15.7287, 15.2897,\n",
      "        14.8128, 14.2416], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([8.7613e-01, 7.9597e-02, 2.4140e-02, 7.1471e-03, 5.5136e-03, 1.8803e-03,\n",
      "        1.0773e-03, 6.9456e-04, 4.3111e-04, 2.4350e-04],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "laittaa \t >> 0.876126229763031\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa [MASK] osoitteeseen amanda. a. myntti @ utu. fi [SEP]\n",
      "viestiä has probability 0.10039646923542023\n",
      "Guesses: sähköpostia postia viestiä viestin kysymyksiä palautetta viestejä sähköpostin osoitteen terveisiä\n",
      "Logits:  tensor([20.9638, 19.5079, 19.0048, 16.3507, 14.9418, 14.8704, 14.5439, 14.2945,\n",
      "        14.1565, 14.1186], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.7120, 0.1660, 0.1004, 0.0071, 0.0017, 0.0016, 0.0012, 0.0009, 0.0008,\n",
      "        0.0008], grad_fn=<SliceBackward0>)\n",
      "viestiä \t >> 0.10039646923542023\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä [MASK] amanda. a. myntti @ utu. fi [SEP]\n",
      "osoitteeseen has probability 0.3348371684551239\n",
      "Guesses: : osoitteeseen sähköpostilla,. sähköpostitse sähköpostiin mulle! osoitteessa\n",
      "Logits:  tensor([17.5481, 17.1322, 15.3608, 14.2926, 13.4750, 13.4220, 13.3789, 13.1901,\n",
      "        12.9349, 12.7685], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.5075, 0.3348, 0.0570, 0.0196, 0.0086, 0.0082, 0.0078, 0.0065, 0.0050,\n",
      "        0.0043], grad_fn=<SliceBackward0>)\n",
      "osoitteeseen \t >> 0.3348371684551239\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen [MASK] [MASK] [MASK]. a. myntti @ utu. fi [SEP]\n",
      "am has probability 0.024157442152500153\n",
      "Guesses: Aman : am hei ai j mar ad johan jo\n",
      "Logits:  tensor([12.6337, 10.6493, 10.5514, 10.5501, 10.3456, 10.3343, 10.3168,  9.9750,\n",
      "         9.9389,  9.9378], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.1938, 0.0266, 0.0242, 0.0241, 0.0197, 0.0194, 0.0191, 0.0136, 0.0131,\n",
      "        0.0131], grad_fn=<SliceBackward0>)\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen am [MASK] [MASK]. a. myntti @ utu. fi [SEP]\n",
      "##and has probability 0.18970882892608643\n",
      "Guesses: ##anddaaanianamahianbe\n",
      "Logits:  tensor([15.8600, 14.0445, 13.9022, 13.8383, 13.6965, 13.3553, 13.2069, 13.1583,\n",
      "        13.1513, 13.0876], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.1897, 0.0309, 0.0268, 0.0251, 0.0218, 0.0155, 0.0134, 0.0127, 0.0126,\n",
      "        0.0119], grad_fn=<SliceBackward0>)\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amand [MASK]. a. myntti @ utu. fi [SEP]\n",
      "##a has probability 0.4848722517490387\n",
      "Guesses: ##aiadaioeraiolaand\n",
      "Logits:  tensor([17.7846, 15.8198, 15.3878, 15.1044, 14.8924, 14.6478, 14.1150, 14.1100,\n",
      "        14.0895, 14.0703], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.4849, 0.0680, 0.0441, 0.0332, 0.0269, 0.0211, 0.0124, 0.0123, 0.0120,\n",
      "        0.0118], grad_fn=<SliceBackward0>)\n",
      "amanda \t >> 0.0022221114486455917 \t >> Redact\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda [MASK] a. myntti @ utu. fi [SEP]\n",
      ". has probability 0.8032383918762207\n",
      "Guesses: . - _ (, : [ / + tai\n",
      "Logits:  tensor([19.1616, 17.2888, 16.1204, 15.5472, 13.7584, 13.2596, 12.9466, 12.1301,\n",
      "        11.9357, 11.8844], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([8.0324e-01, 1.2346e-01, 3.8376e-02, 2.1633e-02, 3.6163e-03, 2.1960e-03,\n",
      "        1.6060e-03, 7.0976e-04, 5.8436e-04, 5.5516e-04],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ". \t >> 0.8032383918762207\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda. [MASK]. myntti @ utu. fi [SEP]\n",
      "a has probability 0.10224533081054688\n",
      "Guesses: o a s m j k d c al af\n",
      "Logits:  tensor([12.7441, 12.4831, 12.0245, 11.4933, 11.2575, 10.8913, 10.7902, 10.6023,\n",
      "        10.4728, 10.4695], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.1327, 0.1022, 0.0646, 0.0380, 0.0300, 0.0208, 0.0188, 0.0156, 0.0137,\n",
      "        0.0137], grad_fn=<SliceBackward0>)\n",
      "a \t >> 0.10224533081054688\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda. a [MASK] myntti @ utu. fi [SEP]\n",
      ". has probability 0.22446376085281372\n",
      "Guesses: -., tai ja _ / & ( )\n",
      "Logits:  tensor([17.8332, 16.8086, 15.5578, 14.3955, 14.2835, 13.6595, 13.0261, 12.7115,\n",
      "        12.2350, 12.2302], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.6254, 0.2245, 0.0643, 0.0201, 0.0180, 0.0096, 0.0051, 0.0037, 0.0023,\n",
      "        0.0023], grad_fn=<SliceBackward0>)\n",
      ". \t >> 0.22446376085281372\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda. a. [MASK] [MASK] [MASK] @ utu. fi [SEP]\n",
      "my has probability 0.0004871261480730027\n",
      "Guesses: w la s o ha an jaa lin san ma\n",
      "Logits:  tensor([10.1935,  9.5416,  9.4600,  9.4512,  9.3181,  9.2020,  9.1773,  8.9943,\n",
      "         8.9673,  8.9448], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.0273, 0.0142, 0.0131, 0.0130, 0.0114, 0.0101, 0.0099, 0.0082, 0.0080,\n",
      "        0.0078], grad_fn=<SliceBackward0>)\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda. a. my [MASK] [MASK] @ utu. fi [SEP]\n",
      "##nt has probability 0.0018640542402863503\n",
      "Guesses: ##lnlidlogtylinsw\n",
      "Logits:  tensor([12.7389, 12.3771, 12.0489, 11.9371, 11.7965, 11.7569, 11.6653, 11.6630,\n",
      "        11.6402, 11.6149], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.0339, 0.0236, 0.0170, 0.0152, 0.0132, 0.0127, 0.0116, 0.0116, 0.0113,\n",
      "        0.0110], grad_fn=<SliceBackward0>)\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda. a. mynt [MASK] @ utu. fi [SEP]\n",
      "##ti has probability 0.007376472465693951\n",
      "Guesses: ##oaieniuseronilaolae\n",
      "Logits:  tensor([16.5169, 16.4019, 15.7852, 15.7205, 15.5410, 15.0099, 14.9506, 14.8831,\n",
      "        14.8074, 14.7720], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.1130, 0.1007, 0.0544, 0.0509, 0.0426, 0.0250, 0.0236, 0.0220, 0.0204,\n",
      "        0.0197], grad_fn=<SliceBackward0>)\n",
      "myntti \t >> 6.6980549995321326e-09 \t >> Redact\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda. a. myntti [MASK] utu. fi [SEP]\n",
      "@ has probability 0.995269238948822\n",
      "Guesses: @ at - ät. ) (, _ /\n",
      "Logits:  tensor([24.3747, 18.0933, 17.4172, 17.2484, 17.1045, 15.7489, 14.8826, 14.1721,\n",
      "        13.7406, 13.4386], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([9.9527e-01, 1.8621e-03, 9.4698e-04, 7.9994e-04, 6.9272e-04, 1.7857e-04,\n",
      "        7.5092e-05, 3.6899e-05, 2.3968e-05, 1.7721e-05],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "@ \t >> 0.995269238948822\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda. a. myntti @ [MASK] [MASK]. fi [SEP]\n",
      "ut has probability 0.014398469589650631\n",
      "Guesses: suomi kolum ilme ut j ni sauna ms y mtv\n",
      "Logits:  tensor([15.2530, 13.2150, 12.4565, 11.5890, 11.4684, 11.4553, 11.3629, 11.2194,\n",
      "        11.2013, 10.9273], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.5618, 0.0732, 0.0343, 0.0144, 0.0128, 0.0126, 0.0115, 0.0099, 0.0098,\n",
      "        0.0074], grad_fn=<SliceBackward0>)\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda. a. myntti @ ut [MASK]. fi [SEP]\n",
      "##u has probability 0.5886359214782715\n",
      "Guesses: ##uaevaeeraeduyeliuvaku\n",
      "Logits:  tensor([20.4216, 19.3831, 17.0023, 16.9497, 16.4506, 16.2799, 16.1624, 15.6661,\n",
      "        15.5352, 15.4423], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.5886, 0.2084, 0.0193, 0.0183, 0.0111, 0.0094, 0.0083, 0.0051, 0.0044,\n",
      "        0.0040], grad_fn=<SliceBackward0>)\n",
      "utu \t >> 0.00847545638680458 \t >> Redact\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda. a. myntti @ utu [MASK] fi [SEP]\n",
      ". has probability 0.9999910593032837\n",
      "Guesses: . -, fi / : piste _ [UNK] )\n",
      "Logits:  tensor([27.4898, 14.4518, 13.9858, 13.8607, 13.4895, 13.4176, 12.9440, 12.5920,\n",
      "        12.3372, 12.0205], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([9.9999e-01, 2.1761e-06, 1.3655e-06, 1.2049e-06, 8.3127e-07, 7.7361e-07,\n",
      "        4.8178e-07, 3.3882e-07, 2.6261e-07, 1.9133e-07],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ". \t >> 0.9999910593032837\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda. a. myntti @ utu. [MASK] [SEP]\n",
      "fi has probability 0.9912620782852173\n",
      "Guesses: fi net com info edu org f nu ut ru\n",
      "Logits:  tensor([21.6515, 15.9073, 15.2113, 13.9613, 13.7729, 13.6632, 13.4043, 13.3931,\n",
      "        13.1256, 13.0009], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([9.9126e-01, 3.1734e-03, 1.5822e-03, 4.5333e-04, 3.7547e-04, 3.3645e-04,\n",
      "        2.5971e-04, 2.5680e-04, 1.9653e-04, 1.7350e-04],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "fi \t >> 0.9912620782852173\n"
     ]
    }
   ],
   "source": [
    "threshold= 0.01\n",
    "text = \"Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda.a.myntti@utu.fi\"\n",
    "masked_indices, tokenized_text, decoded_text = mask(text, tokenizer)\n",
    "for ind in masked_indices:\n",
    "    final_score = get_scores(ind, tokenized_text, debug=True)\n",
    "    word = tokenizer.decode(tokenized_text[\"input_ids\"][0][ind])\n",
    "    if final_score < threshold:\n",
    "        print(f'{word} \\t >> {final_score} \\t >> Redact')\n",
    "    else:\n",
    "        print(f'{word} \\t >> {final_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ee71f81-08dd-4019-8294-41a10474c7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yleisimmät \t >> 0.21354475617408752\n",
      "suomenkieliset \t >> 0.0023188365157693624 \t >> Redact\n",
      "miesten \t >> 0.07334546744823456\n",
      "nimet \t >> 0.8113657236099243\n",
      "ovat \t >> 0.9380959868431091\n",
      "Matti \t >> 0.9777960181236267\n",
      "Meikäläinen \t >> 0.00024416143423877656 \t >> Redact\n",
      ", \t >> 0.9452181458473206\n",
      "Mikko \t >> 0.008687050081789494 \t >> Redact\n",
      ", \t >> 0.973944902420044\n",
      "Tapani \t >> 0.0012471594382077456 \t >> Redact\n",
      ", \t >> 0.9917752742767334\n",
      "Ville \t >> 0.009906979277729988 \t >> Redact\n",
      ", \t >> 0.0925283432006836\n",
      "ja \t >> 0.19433386623859406\n",
      "Vladimir \t >> 0.00017671416571829468 \t >> Redact\n",
      ". \t >> 0.9940406680107117\n"
     ]
    }
   ],
   "source": [
    "threshold= 0.01\n",
    "text = \"Yleisimmät suomenkieliset miesten nimet ovat Matti Meikäläinen, Mikko, Tapani, Ville, ja Vladimir.\"\n",
    "masked_indices, tokenized_text, decoded_text = mask(text, tokenizer)\n",
    "for ind in masked_indices:\n",
    "    final_score = get_scores(ind, tokenized_text, debug=False)\n",
    "    word = tokenizer.decode(tokenized_text[\"input_ids\"][0][ind])\n",
    "    if final_score < threshold:\n",
    "        print(f'{word} \\t >> {final_score} \\t >> Redact')\n",
    "    else:\n",
    "        print(f'{word} \\t >> {final_score}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2365bda-dd38-499c-9baa-1397f853e2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
