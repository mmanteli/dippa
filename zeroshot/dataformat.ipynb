{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47a21bc4-cd0a-4c21-8994-98e06bbc13c8",
   "metadata": {},
   "source": [
    "# Now that the hypothesis is tested, I'm trying to find a good data format for the masking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f8d4943f-865f-4cf2-8f87-cf35658a0a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import datasets\n",
    "import torch\n",
    "import random\n",
    "import copy\n",
    "import itertools\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "874d83c4-21cc-4fdd-a464-e653a4979de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib64/python3.9/site-packages/torch/cuda/__init__.py:611: UserWarning: Can't initialize NVML\n",
      "  warnings.warn(\"Can't initialize NVML\")\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"TurkuNLP/bert-base-finnish-cased-v1\"\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "model = transformers.AutoModelForPreTraining.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08ddbf0d-684d-4c05-b4c3-a2f7beb5da4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[UNK]', '[SEP]', '[PAD]', '[CLS]', '[MASK]']\n"
     ]
    }
   ],
   "source": [
    "special_tokens = tokenizer.all_special_tokens\n",
    "print(special_tokens)\n",
    "continuation_marker = \"##\"   # how to get this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcd58ce6-7d07-4e47-923f-d36220071629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BertTokenizerFast(name_or_path='TurkuNLP/bert-base-finnish-cased-v1', vocab_size=50105, model_max_length=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t101: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t102: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t103: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "\t104: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      "[<class 'transformers.models.bert.tokenization_bert_fast.BertTokenizerFast'>, <class 'transformers.tokenization_utils_fast.PreTrainedTokenizerFast'>, <class 'transformers.tokenization_utils_base.PreTrainedTokenizerBase'>, <class 'transformers.tokenization_utils_base.SpecialTokensMixin'>, <class 'transformers.utils.hub.PushToHubMixin'>, <class 'object'>]\n",
      "['BertTokenizer', 'BertTokenizerFast', 'List', 'Optional', 'PRETRAINED_INIT_CONFIGURATION', 'PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES', 'PRETRAINED_VOCAB_FILES_MAP', 'PreTrainedTokenizerFast', 'Tuple', 'VOCAB_FILES_NAMES', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'json', 'logger', 'logging', 'normalizers']\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer)\n",
    "print(tokenizer.__class__.mro())\n",
    "print(dir(transformers.models.bert.tokenization_bert_fast))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90de0298-a2bc-4d52-b627-a93e525106d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def mask(text, tokenizer):\n",
    "\n",
    "    def get_indices(t):\n",
    "        converted = tokenizer.convert_ids_to_tokens(t[\"input_ids\"][0])\n",
    "        indices=[]\n",
    "        for i in range(0, len(t[\"input_ids\"][0])):\n",
    "            if converted[i][:2] != continuation_marker and converted[i] not in special_tokens:\n",
    "                indices.append([i])\n",
    "            else:\n",
    "                if converted[i] not in special_tokens and indices!=[]:   # here we are only skipping the fact that first token is a special token; indices is empty.\n",
    "                    indices[-1].append(i)\n",
    "        return indices   \n",
    "    \n",
    "    t = tokenizer(text, return_tensors='pt') # prepare normal tokenized input\n",
    "    indices = get_indices(t)\n",
    "\n",
    "    return indices, t, tokenizer.decode(t.input_ids[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d94fef0e-03c2-484f-9a4c-9b02dbe89444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen example @ outlook. com [SEP]\n",
      "[2] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen example @ outlook. com [SEP]\n",
      "[3] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen example @ outlook. com [SEP]\n",
      "[4, 5] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen example @ outlook. com [SEP]\n",
      "[6] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen example @ outlook. com [SEP]\n",
      "[7] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen example @ outlook. com [SEP]\n",
      "[8] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen example @ outlook. com [SEP]\n",
      "[9] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen example @ outlook. com [SEP]\n",
      "[10] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen example @ outlook. com [SEP]\n",
      "[11] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen example @ outlook. com [SEP]\n",
      "[12, 13, 14] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen example @ outlook. com [SEP]\n",
      "[15] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen example @ outlook. com [SEP]\n",
      "[16, 17, 18] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen example @ outlook. com [SEP]\n",
      "[19] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen example @ outlook. com [SEP]\n",
      "[20] [CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen example @ outlook. com [SEP]\n"
     ]
    }
   ],
   "source": [
    "text = \"Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen example@outlook.com\"\n",
    "masked_indices, tokenized_text, decoded_text = mask(text, tokenizer)\n",
    "for i in masked_indices:\n",
    "    print(i, decoded_text)#,tokenized_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b198c6b3-9c4d-4c1e-b3a1-b5992487d385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_probability(A):\n",
    "    softmax = torch.nn.Softmax(dim=0)\n",
    "    return softmax(A)\n",
    "\n",
    "def predict(masked, i, true_token, print_results=False, top=10):\n",
    "    # do a prediction\n",
    "    model_out = model(**masked)\n",
    "    logits = model_out[\"prediction_logits\"]\n",
    "\n",
    "    # logits for this word specifically\n",
    "    logits_i = logits[0,i,:]  # this contains the probabilities for this token\n",
    "    # change to probability\n",
    "    probs = to_probability(logits_i)\n",
    "    # true token is the index\n",
    "    word_probability = probs[true_token]\n",
    "\n",
    "    # Do only in debug mode:\n",
    "    if print_results:\n",
    "        print(f'{tokenizer.decode(true_token)} has probability {word_probability}')\n",
    "        # see 10 top predictions for debug\n",
    "        top_logits, top_tokens= torch.sort(logits, dim=2, descending=True)#[:,:,:top]\n",
    "        top_probs = to_probability(top_logits[0,i,:])\n",
    "        top_logits = top_logits[:,:,:top]\n",
    "        top_tokens = top_tokens[:,:,:top]\n",
    "\n",
    "    \n",
    "        print(\"Guesses:\",tokenizer.decode(top_tokens[0,i,:]))\n",
    "        print(\"Logits: \",top_logits[0,i,:])\n",
    "        print(\"Probs:  \",top_probs[:top])\n",
    "    return word_probability\n",
    "\n",
    "\n",
    "def get_scores(to_be_masked, tokens, debug=False):\n",
    "    \"\"\"\n",
    "    Calculates the (aggregated) probability of the given word based on the model prediction.\n",
    "    For multi-subtoken words, aggregation strategy is gradual unmasking and multiplication.\n",
    "    Input: \n",
    "        tokens: tokenizer output for a span of text\n",
    "        to_be_masked: indices for which are masked from the tokens and over which we calculate\n",
    "                      i.e. indices of the subtokens that form a word.\n",
    "        debug (False): prints out extra information if True\n",
    "    Returns:\n",
    "        (aggregated) probability \\in (0,1)\n",
    "    \"\"\"\n",
    "    # initialize the score; we're multiplying, so 1\n",
    "    final_score = 1\n",
    "\n",
    "    # loop over the subtokens of a word\n",
    "    for i in range(len(to_be_masked)):\n",
    "        # making a deep copy as tensors are nested and yada yada\n",
    "        t = copy.deepcopy(tokens)\n",
    "        current = to_be_masked[i:]   # this is the token we are CURRENTLY interested in\n",
    "        for j in current:\n",
    "            t[\"input_ids\"][0][j] = tokenizer.mask_token_id     # we mask the SUBtokens that are in current\n",
    "        if debug:\n",
    "            print(tokenizer.decode(t[\"input_ids\"][0]))\n",
    "        # multiply the final score with the predicted probability => aggregates over to_be_masked==one word\n",
    "        final_score *= predict(t, current[0], tokens.input_ids[0][current[0]], print_results=debug)\n",
    "        \n",
    "    return final_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59fb3bc0-00be-487a-99b5-c7db6e654560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moi \t >> 0.11190102249383926\n",
      ", \t >> 0.914529025554657\n",
      "olen \t >> 0.09335358440876007\n",
      "Amanda \t >> 2.389645032963017e-06\n",
      ", \t >> 0.1585882604122162\n",
      "mulle \t >> 0.007883135229349136\n",
      "voit \t >> 0.1252748966217041\n",
      "laittaa \t >> 0.8456864356994629\n",
      "viestiä \t >> 0.15869447588920593\n",
      "osoitteeseen \t >> 0.5966525673866272\n",
      "example \t >> 6.858137946430531e-10\n",
      "@ \t >> 0.995366096496582\n",
      "outlook \t >> 3.76461412088247e-06\n",
      ". \t >> 0.9999146461486816\n",
      "com \t >> 0.9127005338668823\n"
     ]
    }
   ],
   "source": [
    "for ind in masked_indices:\n",
    "    final_score = get_scores(ind, tokenized_text, debug=False)\n",
    "    word = tokenizer.decode(tokenized_text[\"input_ids\"][0][ind])\n",
    "    print(f'{word} \\t >> {final_score}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5537391f-7d62-43f5-9585-630f2ab0f04f",
   "metadata": {},
   "source": [
    " ## Actual function \n",
    "\n",
    " Also testing the hypothesis that email screws names over..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d4f76cf-02e6-44e5-891c-5f634ecc5c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moi \t >> 0.11190102249383926\n",
      ", \t >> 0.914529025554657\n",
      "olen \t >> 0.09335358440876007\n",
      "Amanda \t >> 2.389645032963017e-06 \t >> Redact\n",
      ", \t >> 0.1585882604122162\n",
      "mulle \t >> 0.007883135229349136\n",
      "voit \t >> 0.1252748966217041\n",
      "laittaa \t >> 0.8456864356994629\n",
      "viestiä \t >> 0.15869447588920593\n",
      "osoitteeseen \t >> 0.5966525673866272\n",
      "example \t >> 6.858137946430531e-10 \t >> Redact\n",
      "@ \t >> 0.995366096496582\n",
      "outlook \t >> 3.76461412088247e-06 \t >> Redact\n",
      ". \t >> 0.9999146461486816\n",
      "com \t >> 0.9127005338668823\n"
     ]
    }
   ],
   "source": [
    "threshold = 1e-4\n",
    "text = \"Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen example@outlook.com\"\n",
    "masked_indices, tokenized_text, decoded_text = mask(text, tokenizer)\n",
    "for ind in masked_indices:\n",
    "    final_score = get_scores(ind, tokenized_text, debug=False)\n",
    "    word = tokenizer.decode(tokenized_text[\"input_ids\"][0][ind])\n",
    "    if final_score < threshold:\n",
    "        print(f'{word} \\t >> {final_score} \\t >> Redact')\n",
    "    else:\n",
    "        print(f'{word} \\t >> {final_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebbebce5-2b37-4088-a895-087fdfdf6218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moi \t >> 0.1140635758638382\n",
      ", \t >> 0.9137162566184998\n",
      "olen \t >> 0.09167791157960892\n",
      "Amanda \t >> 0.0007409827085211873\n",
      ", \t >> 0.1578478366136551\n",
      "mulle \t >> 0.008461365476250648\n",
      "voit \t >> 0.12811163067817688\n",
      "laittaa \t >> 0.8577243089675903\n",
      "viestiä \t >> 0.1511165201663971\n",
      "osoitteeseen \t >> 0.5203193426132202\n",
      "amanda \t >> 0.000500433670822531\n",
      "@ \t >> 0.9961161613464355\n",
      "outlook \t >> 1.5931143479974708e-06 \t >> Redact\n",
      ". \t >> 0.9999407529830933\n",
      "com \t >> 0.8941934704780579\n"
     ]
    }
   ],
   "source": [
    "text = \"Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda@outlook.com\"\n",
    "masked_indices, tokenized_text, decoded_text = mask(text, tokenizer)\n",
    "for ind in masked_indices:\n",
    "    final_score = get_scores(ind, tokenized_text, debug=False)\n",
    "    word = tokenizer.decode(tokenized_text[\"input_ids\"][0][ind])\n",
    "    if final_score < threshold:\n",
    "        print(f'{word} \\t >> {final_score} \\t >> Redact')\n",
    "    else:\n",
    "        print(f'{word} \\t >> {final_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78de29a5-f5bf-4ac6-a92b-9999356a9255",
   "metadata": {},
   "source": [
    "Sliding window needed...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec8cda5e-535d-4528-8815-529585a04fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] [MASK], olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda. a. myntti @ utu. fi [SEP]\n",
      "Moi has probability 0.0978383794426918\n",
      "Guesses: Hei Moi Niin Muuten Juu hei Joo Minä Eli Kiitos\n",
      "Logits:  tensor([18.0196, 16.0267, 14.7276, 14.0297, 13.9222, 13.8744, 13.7270, 13.6844,\n",
      "        13.5303, 13.0911], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.7178, 0.0978, 0.0267, 0.0133, 0.0119, 0.0114, 0.0098, 0.0094, 0.0081,\n",
      "        0.0052], grad_fn=<SliceBackward0>)\n",
      "Moi \t >> 0.0978383794426918\n",
      "[CLS] Moi [MASK] olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda. a. myntti @ utu. fi [SEP]\n",
      ", has probability 0.9152219891548157\n",
      "Guesses: , ja! :kka Moi mä minä - kun\n",
      "Logits:  tensor([18.5762, 14.9539, 14.9508, 13.2647, 12.7153, 12.5752, 12.1283, 12.1190,\n",
      "        11.9380, 11.7797], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.9152, 0.0245, 0.0244, 0.0045, 0.0026, 0.0023, 0.0014, 0.0014, 0.0012,\n",
      "        0.0010], grad_fn=<SliceBackward0>)\n",
      ", \t >> 0.9152219891548157\n",
      "[CLS] Moi, [MASK] Amanda, mulle voit laittaa viestiä osoitteeseen amanda. a. myntti @ utu. fi [SEP]\n",
      "olen has probability 0.05866996943950653\n",
      "Guesses: Hei hei Moi olen ihana rakas sinä kiitos oon ja\n",
      "Logits:  tensor([14.1292, 14.0475, 13.0499, 12.8344, 12.2256, 12.0267, 11.9355, 11.8929,\n",
      "        11.7187, 11.6651], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.2142, 0.1974, 0.0728, 0.0587, 0.0319, 0.0262, 0.0239, 0.0229, 0.0192,\n",
      "        0.0182], grad_fn=<SliceBackward0>)\n",
      "olen \t >> 0.05866996943950653\n",
      "[CLS] Moi, olen [MASK] [MASK], mulle voit laittaa viestiä osoitteeseen amanda. a. myntti @ utu. fi [SEP]\n",
      "Aman has probability 0.009322038851678371\n",
      "Guesses: kiinnostunut am täällä ihan vasta siis Aman jo Jenni aivan\n",
      "Logits:  tensor([9.5674, 9.2939, 9.0420, 8.5219, 8.4901, 8.2941, 8.2412, 8.1654, 8.0317,\n",
      "        7.8382], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.0351, 0.0267, 0.0208, 0.0123, 0.0120, 0.0098, 0.0093, 0.0086, 0.0076,\n",
      "        0.0062], grad_fn=<SliceBackward0>)\n",
      "[CLS] Moi, olen Aman [MASK], mulle voit laittaa viestiä osoitteeseen amanda. a. myntti @ utu. fi [SEP]\n",
      "##da has probability 0.052135542035102844\n",
      "Guesses: ##adasatajassaissaia kirjoittajai\n",
      "Logits:  tensor([12.1254, 11.1853, 10.7317, 10.6240, 10.5246, 10.0528,  9.8527,  9.7535,\n",
      "         9.7306,  9.6520], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.1335, 0.0521, 0.0331, 0.0297, 0.0269, 0.0168, 0.0138, 0.0125, 0.0122,\n",
      "        0.0113], grad_fn=<SliceBackward0>)\n",
      "Amanda \t >> 0.00048600955051369965 \t >> Redact\n",
      "[CLS] Moi, olen Amanda [MASK] mulle voit laittaa viestiä osoitteeseen amanda. a. myntti @ utu. fi [SEP]\n",
      ", has probability 0.1517307162284851\n",
      "Guesses: ja, eli joten mutta -. mut Ja!\n",
      "Logits:  tensor([18.8184, 17.1285, 13.9340, 13.5213, 13.4964, 12.3079, 12.2653, 12.2091,\n",
      "        12.0952, 12.0819], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.8222, 0.1517, 0.0062, 0.0041, 0.0040, 0.0012, 0.0012, 0.0011, 0.0010,\n",
      "        0.0010], grad_fn=<SliceBackward0>)\n",
      ", \t >> 0.1517307162284851\n",
      "[CLS] Moi, olen Amanda, [MASK] voit laittaa viestiä osoitteeseen amanda. a. myntti @ utu. fi [SEP]\n",
      "mulle has probability 0.005366516765207052\n",
      "Guesses: joten ja mutta eli minulle niin minusta nyt mulle mut\n",
      "Logits:  tensor([17.9620, 16.8124, 16.7235, 15.9874, 15.7551, 15.1396, 14.0246, 13.6029,\n",
      "        13.4692, 13.4233], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.4796, 0.1519, 0.1390, 0.0666, 0.0528, 0.0285, 0.0094, 0.0061, 0.0054,\n",
      "        0.0051], grad_fn=<SliceBackward0>)\n",
      "mulle \t >> 0.005366516765207052 \t >> Redact\n",
      "[CLS] Moi, olen Amanda, mulle [MASK] laittaa viestiä osoitteeseen amanda. a. myntti @ utu. fi [SEP]\n",
      "voit has probability 0.13664209842681885\n",
      "Guesses: voi voit saa kannattaa voitte voisi voipi voisit voin pitää\n",
      "Logits:  tensor([21.0307, 19.3314, 18.5237, 16.9238, 16.8049, 16.3596, 15.9170, 15.8855,\n",
      "        15.6609, 15.6442], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.7475, 0.1366, 0.0609, 0.0123, 0.0109, 0.0070, 0.0045, 0.0044, 0.0035,\n",
      "        0.0034], grad_fn=<SliceBackward0>)\n",
      "voit \t >> 0.13664209842681885\n",
      "[CLS] Moi, olen Amanda, mulle voit [MASK] viestiä osoitteeseen amanda. a. myntti @ utu. fi [SEP]\n",
      "laittaa has probability 0.8761260509490967\n",
      "Guesses: laittaa lähettää pistää heittää jättää kirjoittaa laitta laitaa laita kirjoitella\n",
      "Logits:  tensor([22.4297, 20.0312, 18.8381, 17.6209, 17.3614, 16.2856, 15.7287, 15.2897,\n",
      "        14.8128, 14.2416], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([8.7613e-01, 7.9597e-02, 2.4140e-02, 7.1472e-03, 5.5135e-03, 1.8803e-03,\n",
      "        1.0773e-03, 6.9456e-04, 4.3111e-04, 2.4349e-04],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "laittaa \t >> 0.8761260509490967\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa [MASK] osoitteeseen amanda. a. myntti @ utu. fi [SEP]\n",
      "viestiä has probability 0.10039561986923218\n",
      "Guesses: sähköpostia postia viestiä viestin kysymyksiä palautetta viestejä sähköpostin osoitteen terveisiä\n",
      "Logits:  tensor([20.9637, 19.5079, 19.0048, 16.3507, 14.9418, 14.8703, 14.5439, 14.2945,\n",
      "        14.1565, 14.1186], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.7120, 0.1660, 0.1004, 0.0071, 0.0017, 0.0016, 0.0012, 0.0009, 0.0008,\n",
      "        0.0008], grad_fn=<SliceBackward0>)\n",
      "viestiä \t >> 0.10039561986923218\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä [MASK] amanda. a. myntti @ utu. fi [SEP]\n",
      "osoitteeseen has probability 0.3348364233970642\n",
      "Guesses: : osoitteeseen sähköpostilla,. sähköpostitse sähköpostiin mulle! osoitteessa\n",
      "Logits:  tensor([17.5481, 17.1322, 15.3608, 14.2926, 13.4750, 13.4220, 13.3789, 13.1901,\n",
      "        12.9349, 12.7685], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.5075, 0.3348, 0.0570, 0.0196, 0.0086, 0.0082, 0.0078, 0.0065, 0.0050,\n",
      "        0.0043], grad_fn=<SliceBackward0>)\n",
      "osoitteeseen \t >> 0.3348364233970642\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen [MASK] [MASK] [MASK]. a. myntti @ utu. fi [SEP]\n",
      "am has probability 0.02415752224624157\n",
      "Guesses: Aman : am hei ai j mar ad johan jo\n",
      "Logits:  tensor([12.6337, 10.6493, 10.5514, 10.5501, 10.3456, 10.3343, 10.3168,  9.9750,\n",
      "         9.9389,  9.9378], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.1938, 0.0266, 0.0242, 0.0241, 0.0197, 0.0194, 0.0191, 0.0136, 0.0131,\n",
      "        0.0131], grad_fn=<SliceBackward0>)\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen am [MASK] [MASK]. a. myntti @ utu. fi [SEP]\n",
      "##and has probability 0.18970929086208344\n",
      "Guesses: ##anddaaanianamahianbe\n",
      "Logits:  tensor([15.8600, 14.0445, 13.9022, 13.8383, 13.6965, 13.3553, 13.2069, 13.1583,\n",
      "        13.1513, 13.0876], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.1897, 0.0309, 0.0268, 0.0251, 0.0218, 0.0155, 0.0134, 0.0127, 0.0126,\n",
      "        0.0119], grad_fn=<SliceBackward0>)\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amand [MASK]. a. myntti @ utu. fi [SEP]\n",
      "##a has probability 0.4848712384700775\n",
      "Guesses: ##aiadaioeraiolaand\n",
      "Logits:  tensor([17.7846, 15.8198, 15.3878, 15.1044, 14.8924, 14.6478, 14.1150, 14.1100,\n",
      "        14.0895, 14.0703], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.4849, 0.0680, 0.0441, 0.0332, 0.0269, 0.0211, 0.0124, 0.0123, 0.0120,\n",
      "        0.0118], grad_fn=<SliceBackward0>)\n",
      "amanda \t >> 0.0022221195977181196 \t >> Redact\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda [MASK] a. myntti @ utu. fi [SEP]\n",
      ". has probability 0.8032384514808655\n",
      "Guesses: . - _ (, : [ / + tai\n",
      "Logits:  tensor([19.1616, 17.2888, 16.1204, 15.5472, 13.7584, 13.2596, 12.9466, 12.1301,\n",
      "        11.9357, 11.8844], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([8.0324e-01, 1.2346e-01, 3.8376e-02, 2.1633e-02, 3.6163e-03, 2.1960e-03,\n",
      "        1.6060e-03, 7.0976e-04, 5.8436e-04, 5.5516e-04],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ". \t >> 0.8032384514808655\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda. [MASK]. myntti @ utu. fi [SEP]\n",
      "a has probability 0.10224521905183792\n",
      "Guesses: o a s m j k d c al af\n",
      "Logits:  tensor([12.7441, 12.4831, 12.0245, 11.4933, 11.2575, 10.8913, 10.7902, 10.6023,\n",
      "        10.4728, 10.4695], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.1327, 0.1022, 0.0646, 0.0380, 0.0300, 0.0208, 0.0188, 0.0156, 0.0137,\n",
      "        0.0137], grad_fn=<SliceBackward0>)\n",
      "a \t >> 0.10224521905183792\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda. a [MASK] myntti @ utu. fi [SEP]\n",
      ". has probability 0.22446390986442566\n",
      "Guesses: -., tai ja _ / & ( )\n",
      "Logits:  tensor([17.8332, 16.8086, 15.5578, 14.3955, 14.2835, 13.6595, 13.0261, 12.7115,\n",
      "        12.2350, 12.2302], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.6254, 0.2245, 0.0643, 0.0201, 0.0180, 0.0096, 0.0051, 0.0037, 0.0023,\n",
      "        0.0023], grad_fn=<SliceBackward0>)\n",
      ". \t >> 0.22446390986442566\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda. a. [MASK] [MASK] [MASK] @ utu. fi [SEP]\n",
      "my has probability 0.00048712469288147986\n",
      "Guesses: w la s o ha an jaa lin san ma\n",
      "Logits:  tensor([10.1935,  9.5416,  9.4600,  9.4512,  9.3181,  9.2020,  9.1773,  8.9943,\n",
      "         8.9673,  8.9448], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.0273, 0.0142, 0.0131, 0.0130, 0.0114, 0.0101, 0.0099, 0.0082, 0.0080,\n",
      "        0.0078], grad_fn=<SliceBackward0>)\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda. a. my [MASK] [MASK] @ utu. fi [SEP]\n",
      "##nt has probability 0.0018640548223629594\n",
      "Guesses: ##lnlidlogtylinsw\n",
      "Logits:  tensor([12.7389, 12.3770, 12.0489, 11.9371, 11.7965, 11.7569, 11.6653, 11.6630,\n",
      "        11.6402, 11.6149], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.0339, 0.0236, 0.0170, 0.0152, 0.0132, 0.0127, 0.0116, 0.0116, 0.0113,\n",
      "        0.0110], grad_fn=<SliceBackward0>)\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda. a. mynt [MASK] @ utu. fi [SEP]\n",
      "##ti has probability 0.007376472000032663\n",
      "Guesses: ##oaieniuseronilaolae\n",
      "Logits:  tensor([16.5169, 16.4019, 15.7852, 15.7205, 15.5410, 15.0099, 14.9506, 14.8831,\n",
      "        14.8074, 14.7720], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.1130, 0.1007, 0.0544, 0.0509, 0.0426, 0.0250, 0.0236, 0.0220, 0.0204,\n",
      "        0.0197], grad_fn=<SliceBackward0>)\n",
      "myntti \t >> 6.698036791874529e-09 \t >> Redact\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda. a. myntti [MASK] utu. fi [SEP]\n",
      "@ has probability 0.995269238948822\n",
      "Guesses: @ at - ät. ) (, _ /\n",
      "Logits:  tensor([24.3747, 18.0933, 17.4172, 17.2484, 17.1045, 15.7489, 14.8826, 14.1721,\n",
      "        13.7406, 13.4386], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([9.9527e-01, 1.8620e-03, 9.4697e-04, 7.9993e-04, 6.9271e-04, 1.7857e-04,\n",
      "        7.5092e-05, 3.6898e-05, 2.3968e-05, 1.7720e-05],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "@ \t >> 0.995269238948822\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda. a. myntti @ [MASK] [MASK]. fi [SEP]\n",
      "ut has probability 0.01439853385090828\n",
      "Guesses: suomi kolum ilme ut j ni sauna ms y mtv\n",
      "Logits:  tensor([15.2530, 13.2150, 12.4565, 11.5890, 11.4684, 11.4553, 11.3629, 11.2194,\n",
      "        11.2013, 10.9273], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.5618, 0.0732, 0.0343, 0.0144, 0.0128, 0.0126, 0.0115, 0.0099, 0.0098,\n",
      "        0.0074], grad_fn=<SliceBackward0>)\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda. a. myntti @ ut [MASK]. fi [SEP]\n",
      "##u has probability 0.5886364579200745\n",
      "Guesses: ##uaevaeeraeduyeliuvaku\n",
      "Logits:  tensor([20.4216, 19.3831, 17.0023, 16.9497, 16.4506, 16.2799, 16.1624, 15.6661,\n",
      "        15.5352, 15.4423], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([0.5886, 0.2084, 0.0193, 0.0183, 0.0111, 0.0094, 0.0083, 0.0051, 0.0044,\n",
      "        0.0040], grad_fn=<SliceBackward0>)\n",
      "utu \t >> 0.008475502021610737 \t >> Redact\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda. a. myntti @ utu [MASK] fi [SEP]\n",
      ". has probability 0.9999910593032837\n",
      "Guesses: . -, fi / : piste _ [UNK] )\n",
      "Logits:  tensor([27.4898, 14.4518, 13.9858, 13.8607, 13.4895, 13.4176, 12.9440, 12.5920,\n",
      "        12.3372, 12.0205], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([9.9999e-01, 2.1761e-06, 1.3655e-06, 1.2049e-06, 8.3126e-07, 7.7362e-07,\n",
      "        4.8178e-07, 3.3883e-07, 2.6261e-07, 1.9133e-07],\n",
      "       grad_fn=<SliceBackward0>)\n",
      ". \t >> 0.9999910593032837\n",
      "[CLS] Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda. a. myntti @ utu. [MASK] [SEP]\n",
      "fi has probability 0.9912620782852173\n",
      "Guesses: fi net com info edu org f nu ut ru\n",
      "Logits:  tensor([21.6515, 15.9073, 15.2113, 13.9613, 13.7729, 13.6632, 13.4043, 13.3930,\n",
      "        13.1256, 13.0009], grad_fn=<SliceBackward0>)\n",
      "Probs:   tensor([9.9126e-01, 3.1734e-03, 1.5822e-03, 4.5332e-04, 3.7547e-04, 3.3645e-04,\n",
      "        2.5971e-04, 2.5680e-04, 1.9653e-04, 1.7350e-04],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "fi \t >> 0.9912620782852173\n"
     ]
    }
   ],
   "source": [
    "threshold= 0.01\n",
    "text = \"Moi, olen Amanda, mulle voit laittaa viestiä osoitteeseen amanda.a.myntti@utu.fi\"\n",
    "masked_indices, tokenized_text, decoded_text = mask(text, tokenizer)\n",
    "for ind in masked_indices:\n",
    "    final_score = get_scores(ind, tokenized_text, debug=True)\n",
    "    word = tokenizer.decode(tokenized_text[\"input_ids\"][0][ind])\n",
    "    if final_score < threshold:\n",
    "        print(f'{word} \\t >> {final_score} \\t >> Redact')\n",
    "    else:\n",
    "        print(f'{word} \\t >> {final_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2ee71f81-08dd-4019-8294-41a10474c7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yleisimmät \t >> 0.21354542672634125\n",
      "suomenkieliset \t >> 0.0023188216146081686 \t >> Redact\n",
      "miesten \t >> 0.07334600389003754\n",
      "nimet \t >> 0.811363935470581\n",
      "ovat \t >> 0.9380959868431091\n",
      "Matti \t >> 0.9777957797050476\n",
      "Meikäläinen \t >> 0.00024416312226094306 \t >> Redact\n",
      ", \t >> 0.9452178478240967\n",
      "Mikko \t >> 0.008687094785273075 \t >> Redact\n",
      ", \t >> 0.9739446640014648\n",
      "Tapani \t >> 0.0012471543159335852 \t >> Redact\n",
      ", \t >> 0.9917752742767334\n",
      "Ville \t >> 0.009906980209052563 \t >> Redact\n",
      ", \t >> 0.09252742677927017\n",
      "ja \t >> 0.19433434307575226\n",
      "Vladimir \t >> 0.0001767138164723292 \t >> Redact\n",
      ". \t >> 0.9940406680107117\n"
     ]
    }
   ],
   "source": [
    "threshold= 0.01\n",
    "text = \"Yleisimmät suomenkieliset miesten nimet ovat Matti Meikäläinen, Mikko, Tapani, Ville, ja Vladimir.\"\n",
    "masked_indices, tokenized_text, decoded_text = mask(text, tokenizer)\n",
    "for ind in masked_indices:\n",
    "    final_score = get_scores(ind, tokenized_text, debug=False)\n",
    "    word = tokenizer.decode(tokenized_text[\"input_ids\"][0][ind])\n",
    "    if final_score < threshold:\n",
    "        print(f'{word} \\t >> {final_score} \\t >> Redact')\n",
    "    else:\n",
    "        print(f'{word} \\t >> {final_score}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2365bda-dd38-499c-9baa-1397f853e2a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
